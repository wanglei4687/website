---
title: Pulumi部署operator和crds (eks, cn)
date: '2022-06-07'
tags: ['pulumi', 'aws', 'federated kubernetes cluster']
draft: false
summary: 'In this article we introduce deploy helm charts and custom resource by pulumi'
canonicalUrl: https://github.com/wanglei4687/website/blob/main/data/blog/IaC/pulumi-aws.mdx
---

<TOCInline toc={props.toc} asDisclosure />

## 简介

[pulumi](https://www.pulumi.com/)是`infrastructure as code`的一种工具，可以通过代码的方式管理基础设施（如aws，gke，aliyun等)

## pulumi 和 terraform 的区别

terraform使用了[HCL](https://www.terraform.io/language/syntax/configuration)语法来配置基础设施文件。已有[sdk for terraform](https://www.terraform.io/cdktf)
支持以`go`等语言的方式编写。
![tf_sdk](https://mktg-content-api-hashicorp.vercel.app/api/assets?product=terraform-cdk&version=refs%2Fheads%2Fstable-website&asset=website%2Fdocs%2Fcdktf%2Fterraform-platform.png&width=1776&height=1317)

pulumi 主要使用`go`,`typescript`等编程语言来编写基础设施管理代码。通过stack来区分不同的基础设施，可以理解为类似GitHub branch的方式来管理不同的开发环境。
![plu_sdk](https://www.pulumi.com/images/docs/pulumi-programming-model-diagram.svg)

对于`HCL`语法会有上手的难度，所以对于开发人员来说不太友好，其次是有些基础设施代码的复用更贴合开发人员的习惯。
`pulumi`的优势在于通过代码的方式减少了入门的难度，笔者对于未来的方向来说是以类似`go`等语言的方式为主，类似于`k8s`中`yaml`配置到
`operator`配置的一个转变。这里有一个笔者的观念：传统意义上的运维和测试在云原生的开发上是不太使用的，应该将测试和运维都看作一个开发领域，
也应该将运维（基础设施）开发算作一个开发的域，运用程序设计方法和领域驱动设计来开发基础设施应用。


# pulumi aws 配置

## 获取可用区配置

这里需要在aws的配置中设置账户的区域（类似cn-northwest-1)，在下面创建子网和节点组的时候会在每个可用区下创建一个
节点组（这里可以配置最大值`zoneNumber`来控制最大的节点组数量）。

```go
azState := "available"
zoneList, err := aws.GetAvailabilityZones(ctx, &aws.GetAvailabilityZonesArgs{
	State: &azState,
})
if err != nil {
	return err
}

```

## vpc配置

[Amazn Virtual Private Cloud(Amazon VPC)](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-vpc.html)

- 保护和监控连接、筛选流量，并限制对虚拟网络的示例的访问
- 用更少的时间设置、管理和验证虚拟网络
- 选择自己的IP地址范围、创建子网并配置路由表，以自定义虚拟网络

![vpc](https://d1.awsstatic.com/Digital%20Marketing/House/Hero/products/ec2/VPC/Product-Page-Diagram_Amazon-VPC_HIW.9c472d7f2eb39ab8bdd22aa3ab80be00cdd00d8f.png)

这里更多的还是控制区域内的可用区内`ec2`[网络](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-networking.html)的连接

![aws_vpc](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/images/default-vpc.png)


```go
vpc, err := ec2.NewVpc(ctx, "mo-pulumi-vpc", &ec2.VpcArgs{
     CidrBlock:          pulumi.String("10.0.0.0/16"),
     EnableDnsHostnames: pulumi.Bool(true),
     EnableDnsSupport:   pulumi.Bool(true),
     Tags: pulumi.StringMap{
		"Name": pulumi.String("mo-pulumi-vpc"),
	},
})
```

## 子网配置

[子网](https://docs.aws.amazon.com/vpc/latest/userguide/configure-subnets.html)是可用区内部访问的一种网络配置,
这里在每个可用区都创建一个子网用于`ec2`连接

```go
var subnets []*ec2.Subnet

for i := 0; i < zoneNumber; i++ {
	subnet, err := ec2.NewSubnet(ctx, "mo-pulumi-subnet-"+strconv.Itoa(i), &ec2.SubnetArgs{
		AvailabilityZone: pulumi.String(zoneList.Names[i]),
		Tags: pulumi.StringMap{
			"Name": pulumi.String("mo-pulumi-subnet" + strconv.Itoa(i)),
		},
		VpcId:               vpc.ID(),
		CidrBlock:           pulumi.String("10.0." + strconv.Itoa(i) + ".0/24"),
		MapPublicIpOnLaunch: pulumi.Bool(true),
	})

	if err != nil {
		return err
	}

	subnets = append(subnets, subnet)

}

```

## [互联网网关](https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Internet_Gateway.html)配置

`internet gateway`用于连接外部网络

```go
igw, err := ec2.NewInternetGateway(ctx, "mo-pulumi-gw", &ec2.InternetGatewayArgs{
     	VpcId: vpc.ID(),
})
if err != nil {
   	return err
}
```

## 配置路由表

这里依赖于`vpc`, `internet gateway`, `subnets`的创建，在创建整个部署的管道的时候要配置好依赖，有可能
会在删除的时候出现无法删除的情况。[路由表](https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Route_Tables.html)包含一组称为路由的规则，这些规则确定来自子网或网关的网络流量被定向到何处。

![routetable](https://docs.aws.amazon.com/vpc/latest/userguide/images/case-3_updated.png)

```go
_, err = ec2.NewDefaultRouteTable(ctx, "mo-pulumi-routetable", &ec2.DefaultRouteTableArgs{
	DefaultRouteTableId: vpc.DefaultRouteTableId,
	Routes: ec2.DefaultRouteTableRouteArray{
		ec2.DefaultRouteTableRouteInput(&ec2.DefaultRouteTableRouteArgs{
			CidrBlock: pulumi.String("0.0.0.0/0"),
			GatewayId: igw.ID(),
		}),
	},
}, pulumi.DependsOn([]pulumi.Resource{vpc, igw, subnets[zoneNumber-1]}))
if err != nil {
	return nil
}
```

## 策略配置

这里主要的一个问题是不同区域的[用户策略](https://docs.aws.amazon.com/eks/latest/userguide/service_IAM_role.html
)是有可能不一样的，所以配置了两个区域的策略。

```go
// https://docs.aws.amazon.com/eks/latest/userguide/service_IAM_role.html
eksRole, err := iam.NewRole(ctx, "eks-iam-eksRole", &iam.RoleArgs{
	AssumeRolePolicy: pulumi.String(`{
		    "Version": "2008-10-17",
		    "Statement": [{
		        "Sid": "",
		        "Effect": "Allow",
		        "Principal": {
		            "Service": "eks.amazonaws.com"
		        },
		        "Action": "sts:AssumeRole"
		    }]
		}`),
})

if err != nil {
	return err
}

eksPolicies := []string{
	"arn:aws:iam::aws:policy/AmazonEKSServicePolicy",
	"arn:aws:iam::aws:policy/AmazonEKSClusterPolicy",
}
nodeGroupPolicies := []string{
	"arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy",
	"arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy",
	"arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly",
}
assumeRolePolicy := pulumi.String(`{
		    "Version": "2012-10-17",
		    "Statement": [{
		        "Sid": "",
		        "Effect": "Allow",
		        "Principal": {
		            "Service": "ec2.amazonaws.com"
		        },
		        "Action": "sts:AssumeRole"
		    }]
		}`)

if rcn {
	eksPolicies = []string{
		"arn:aws-cn:iam::aws:policy/AmazonEKSServicePolicy",
		"arn:aws-cn:iam::aws:policy/AmazonEKSClusterPolicy",
	}

	nodeGroupPolicies = []string{
		"arn:aws-cn:iam::aws:policy/AmazonEKSWorkerNodePolicy",
		"arn:aws-cn:iam::aws:policy/AmazonEKS_CNI_Policy",
		"arn:aws-cn:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly",
	}

	assumeRolePolicy = pulumi.String(`{
		    "Version": "2012-10-17",
		    "Statement": [{
		        "Sid": "",
		        "Effect": "Allow",
		        "Principal": {
		            "Service": "ec2.amazonaws.com.cn"
		        },
		        "Action": "sts:AssumeRole"
		    }]
		}`)
}

for i, eksPolicy := range eksPolicies {
	_, err := iam.NewRolePolicyAttachment(ctx, fmt.Sprintf("rpa-%d", i), &iam.RolePolicyAttachmentArgs{
		PolicyArn: pulumi.String(eksPolicy),
		Role:      eksRole.Name,
	})
	if err != nil {
		return err
	}
}

nodeGroupRole, err := iam.NewRole(ctx, "nodegroup-iam-role", &iam.RoleArgs{
	AssumeRolePolicy: assumeRolePolicy,
})
if err != nil {
	return err
}

for i, nodeGroupPolicy := range nodeGroupPolicies {
	_, err := iam.NewRolePolicyAttachment(ctx, fmt.Sprintf("ngpa-%d", i), &iam.RolePolicyAttachmentArgs{
		Role:      nodeGroupRole.Name,
		PolicyArn: pulumi.String(nodeGroupPolicy),
	})
	if err != nil {
		return err
	}
}
```

## 安全组配置

[安全组](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/working-with-security-groups.html)就相当于防火墙的作用，控制进出流量（感觉类似`iptables` 🧐)

```go
sg, err := ec2.NewSecurityGroup(ctx, "mo-pulumi-sg", &ec2.SecurityGroupArgs{
	Description: pulumi.String("security group for ec2 nodes"),
	Name:        pulumi.String("mo-pulumi-sg"),
	VpcId:       vpc.ID(),
	Egress: ec2.SecurityGroupEgressArray{
		ec2.SecurityGroupEgressArgs{
			Protocol:   pulumi.String("-1"),
			FromPort:   pulumi.Int(0),
			ToPort:     pulumi.Int(0),
			CidrBlocks: pulumi.StringArray{pulumi.String("10.10.0.0/20")},
		},
	},
	Ingress: ec2.SecurityGroupIngressArray{
		ec2.SecurityGroupIngressArgs{
			Protocol:   pulumi.String("tcp"),
			FromPort:   pulumi.Int(80),
			ToPort:     pulumi.Int(80),
			CidrBlocks: pulumi.StringArray{pulumi.String("20.20.0.0/20")},
		},
	},
}, pulumi.DependsOn([]pulumi.Resource{vpc, subnets[zoneNumber-1]}))
if err != nil {
	return err
}
```

## eks集群创建

这里单独把`publicAccessCidrs`单独配置也是处于安全考虑，控制连接集群的`IP`范围

```go
eksCluster, err := eks.NewCluster(ctx, "mo-pulumi-eks-cluster", &eks.ClusterArgs{
	RoleArn: pulumi.StringInput(eksRole.Arn),
	VpcConfig: &eks.ClusterVpcConfigArgs{
		PublicAccessCidrs: pulumi.StringArray{
			publicAccessCidrs,
		},
		SecurityGroupIds: pulumi.StringArray{
			sg.ID().ToStringOutput(),
		},
		SubnetIds: toSubnetsArray(subnets),
	},
})
if err != nil {
	return err
}
```

## 创建节点组

这里需要注意一点是节点组的配置，包括磁盘容量，实例类型。需要做一下账单预估🤔

```go
var nodeGroups []*eks.NodeGroup

for i := 0; i < zoneNumber; i++ {
	ng, err := eks.NewNodeGroup(ctx, "mo-pulumi-ng-"+strconv.Itoa(i), &eks.NodeGroupArgs{
		ClusterName:   eksCluster.Name,
		NodeGroupName: pulumi.String("mo-pulumi-ng" + strconv.Itoa(i)),
		NodeRoleArn:   pulumi.StringInput(nodeGroupRole.Arn),
		SubnetIds:     toSubnetsArray(subnets),
		InstanceTypes: utils.ToPulumiStringArray(icfg.Types),
		ScalingConfig: eks.NodeGroupScalingConfigArgs{
			DesiredSize: pulumi.Int(1),
			MaxSize:     pulumi.Int(1),
			MinSize:     pulumi.Int(1),
		},
		DiskSize: pulumi.Int(icfg.diskSize),
		Labels: pulumi.StringMap{
			"Name": pulumi.String("mo-pulumi-ng" + strconv.Itoa(i)),
		},
	}, pulumi.DependsOn([]pulumi.Resource{eksCluster, subnets[zoneNumber-1]}))
	if err != nil {
		return err
	}

	nodeGroups = append(nodeGroups, ng)
}
```

## k8s配置

这里可以通过`pulumi stack output kubeconfig > kubeconfig.yml`导出集群的配置，`k8sProvider`主要的作用是为了下面安装`helm charts`和`Custom Resource`提供依赖支持。

```go
ctx.Export("kubeconfig", generateKubeconfig(eksCluster.Endpoint,
	eksCluster.CertificateAuthority.Data().Elem(), eksCluster.Name))

k8sProvider, err := kubernetes.NewProvider(ctx, "k8s", &kubernetes.ProviderArgs{
	Kubeconfig: generateKubeconfig(eksCluster.Endpoint, eksCluster.CertificateAuthority.Data().Elem(), eksCluster.Name),
}, pulumi.DependsOn([]pulumi.Resource{nodeGroups[0]}))
if err != nil {
	return err
}

//Create the KubeConfig Structure as per https://docs.aws.amazon.com/eks/latest/userguide/create-kubeconfig.html
func generateKubeconfig(clusterEndpoint pulumi.StringOutput, certData pulumi.StringOutput, clusterName pulumi.StringOutput) pulumi.StringOutput {
	return pulumi.Sprintf(`{
        "apiVersion": "v1",
        "clusters": [{
            "cluster": {
                "server": "%s",
                "certificate-authority-data": "%s"
            },
            "name": "kubernetes",
        }],
        "contexts": [{
            "context": {
                "cluster": "kubernetes",
                "user": "aws",
            },
            "name": "aws",
        }],
        "current-context": "aws",
        "kind": "Config",
        "users": [{
            "name": "aws",
            "user": {
                "exec": {
                    "apiVersion": "client.authentication.k8s.io/v1beta1",
                    "command": "aws-iam-authenticator",
                    "args": [
                        "token",
                        "-i",
                        "%s",
                    ],
                },
            },
        }],
    }`, clusterEndpoint, certData, clusterName)
}
```

## helm charts 部署operator和自定义集群安装

这里的`charts`是通过`helm.NewRelease`这个方式部署的，可以配置`values`（即`values.yml`暴露的配置选项）

```go
if installMOCluster || installOp {
		opNS, err := createNS(ctx, k8sProvider, "matrixone-operator")
		if err != nil {
			return err
		}

		_, err = helm.NewRelease(ctx, "operator-helm", &helm.ReleaseArgs{
			Chart: pulumi.String("matrixone-operator"),
			RepositoryOpts: helm.RepositoryOptsArgs{
				Repo: pulumi.String("https://matrixorigin.github.io/matrixone-operator"),
			},
			Version:   pulumi.String("0.1.0"),
			Namespace: opNS.Metadata.Name(),
			SkipAwait: pulumi.BoolPtr(true),
		}, pulumi.Provider(k8sProvider), pulumi.DependsOn([]pulumi.Resource{opNS}))
		if err != nil {
			return err
		}

		if installMOCluster && !installOp {
			moNS, err := createNS(ctx, k8sProvider, "matrixone")
			if err != nil {
				return err
			}

			_, err = apiextensions.NewCustomResource(ctx, "mo-cluster", &apiextensions.CustomResourceArgs{
				ApiVersion: pulumi.String("matrixone.matrixorigin.cn/v1alpha1"),
				Kind:       pulumi.String("MatrixoneCluster"),
				Metadata: &metav1.ObjectMetaArgs{
					Name:      pulumi.String("mo"),
					Namespace: moNS.Metadata.Name(),
				},
				OtherFields: kubernetes.UntypedArgs{
					"spec": map[string]interface{}{
						"image":           pulumi.String("matrixorigin/matrixone:0.4.0"),
						"imagePullPolicy": pulumi.String("Always"),
						"replicas":        pulumi.Int(1),
						"requests": pulumi.Map{
							"cpu": pulumi.String("200m"),
						},
						"podName": pulumi.Map{
							"name": pulumi.String("POD_NAME"),
							"valueFrom": pulumi.Map{
								"fieldRef": pulumi.Map{
									"fieldPath": pulumi.String("metadata.name"),
								},
							},
						},
						"logVolumeCap":  pulumi.String("10Gi"),
						"dataVolumeCap": pulumi.String("10Gi"),
					},
				},
			}, pulumi.Provider(k8sProvider), pulumi.DependsOn([]pulumi.Resource{moNS}))
			if err != nil {
				return err
			}
		}

	}

	return nil
}

```


# 跨区域集群创建

跨区域或者跨云创建集群是需要有一个控制平面（如`rancher`, `crossplane`，`kubefed`)这种，
同时在跨集群调度的时候需要考虑异构计算，网络配置等问题。


[aws 联邦集群方案](https://github.com/awslabs/federated-amazon-eks-clusters-on-aws)

![aws_federated](https://d1.awsstatic.com/Solutions/Solutions%20Category%20Template%20Draft/Solution%20Architecture%20Diagrams/federated-eks-clusters-ra.12d7f93988d634ebf16d60ed4be42a0bac92c7ed.png)

# 全部代码


```go
package aws

import (
	"fmt"
	"log"
	"strconv"

	"github.com/pulumi/pulumi-aws/sdk/v5/go/aws"
	"github.com/pulumi/pulumi-aws/sdk/v5/go/aws/ec2"
	"github.com/pulumi/pulumi-aws/sdk/v5/go/aws/eks"
	"github.com/pulumi/pulumi-aws/sdk/v5/go/aws/iam"
	"github.com/pulumi/pulumi-kubernetes/sdk/v3/go/kubernetes"
	apiextensions "github.com/pulumi/pulumi-kubernetes/sdk/v3/go/kubernetes/apiextensions"
	corev1 "github.com/pulumi/pulumi-kubernetes/sdk/v3/go/kubernetes/core/v1"
	"github.com/pulumi/pulumi-kubernetes/sdk/v3/go/kubernetes/helm/v3"
	metav1 "github.com/pulumi/pulumi-kubernetes/sdk/v3/go/kubernetes/meta/v1"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi/config"
)

type InstanceCfg struct {
	Types    []string
	diskSize int
}

func EKSDeploy(ctx *pulumi.Context, cfg *config.Config) error {
	var icfg InstanceCfg
	zoneNumber := cfg.GetInt("zoneNumber")
	installOp := cfg.GetBool("installOp")
	publicAccessCidrs := cfg.GetSecret("publicAccessCidrs")
	installMOCluster := cfg.GetBool("installMOCluster")
	rcn := cfg.GetBool("regionCN")

	cfg.RequireObject("instance", &icfg)

	// https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-vpc.html
	vpc, err := ec2.NewVpc(ctx, "mo-pulumi-vpc", &ec2.VpcArgs{
		CidrBlock:          pulumi.String("10.0.0.0/16"),
		EnableDnsHostnames: pulumi.Bool(true),
		EnableDnsSupport:   pulumi.Bool(true),
		Tags: pulumi.StringMap{
			"Name": pulumi.String("mo-pulumi-vpc"),
		},
	})
	if err != nil {
		return err
	}

	ctx.Export("VPC_ID", vpc.ID())

	// https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html
	azState := "available"
	zoneList, err := aws.GetAvailabilityZones(ctx, &aws.GetAvailabilityZonesArgs{
		State: &azState,
	})
	if err != nil {
		return err
	}

	if zoneNumber == 0 {
		zoneNumber = len(zoneList.Names)
	} else if zoneNumber <= 0 {
		log.Fatal("zoneNumber >= 0 !!! ")
	}

	// https://docs.aws.amazon.com/vpc/latest/userguide/configure-subnets.html
	var subnets []*ec2.Subnet

	for i := 0; i < zoneNumber; i++ {
		subnet, err := ec2.NewSubnet(ctx, "mo-pulumi-subnet-"+strconv.Itoa(i), &ec2.SubnetArgs{
			AvailabilityZone: pulumi.String(zoneList.Names[i]),
			Tags: pulumi.StringMap{
				"Name": pulumi.String("mo-pulumi-subnet" + strconv.Itoa(i)),
			},
			VpcId:               vpc.ID(),
			CidrBlock:           pulumi.String("10.0." + strconv.Itoa(i) + ".0/24"),
			MapPublicIpOnLaunch: pulumi.Bool(true),
		})

		if err != nil {
			return err
		}

		subnets = append(subnets, subnet)

	}

	igw, err := ec2.NewInternetGateway(ctx, "mo-pulumi-gw", &ec2.InternetGatewayArgs{
		VpcId: vpc.ID(),
	})
	if err != nil {
		return err
	}

	// https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Route_Tables.html
	_, err = ec2.NewDefaultRouteTable(ctx, "mo-pulumi-routetable", &ec2.DefaultRouteTableArgs{
		DefaultRouteTableId: vpc.DefaultRouteTableId,
		Routes: ec2.DefaultRouteTableRouteArray{
			ec2.DefaultRouteTableRouteInput(&ec2.DefaultRouteTableRouteArgs{
				CidrBlock: pulumi.String("0.0.0.0/0"),
				GatewayId: igw.ID(),
			}),
		},
	}, pulumi.DependsOn([]pulumi.Resource{vpc, igw, subnets[zoneNumber-1]}))
	if err != nil {
		return nil
	}

	// https://docs.aws.amazon.com/eks/latest/userguide/service_IAM_role.html
	eksRole, err := iam.NewRole(ctx, "eks-iam-eksRole", &iam.RoleArgs{
		AssumeRolePolicy: pulumi.String(`{
		    "Version": "2008-10-17",
		    "Statement": [{
		        "Sid": "",
		        "Effect": "Allow",
		        "Principal": {
		            "Service": "eks.amazonaws.com"
		        },
		        "Action": "sts:AssumeRole"
		    }]
		}`),
	})

	if err != nil {
		return err
	}

	eksPolicies := []string{
		"arn:aws:iam::aws:policy/AmazonEKSServicePolicy",
		"arn:aws:iam::aws:policy/AmazonEKSClusterPolicy",
	}
	nodeGroupPolicies := []string{
		"arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy",
		"arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy",
		"arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly",
	}
	assumeRolePolicy := pulumi.String(`{
		    "Version": "2012-10-17",
		    "Statement": [{
		        "Sid": "",
		        "Effect": "Allow",
		        "Principal": {
		            "Service": "ec2.amazonaws.com"
		        },
		        "Action": "sts:AssumeRole"
		    }]
		}`)

	if rcn {
		eksPolicies = []string{
			"arn:aws-cn:iam::aws:policy/AmazonEKSServicePolicy",
			"arn:aws-cn:iam::aws:policy/AmazonEKSClusterPolicy",
		}

		nodeGroupPolicies = []string{
			"arn:aws-cn:iam::aws:policy/AmazonEKSWorkerNodePolicy",
			"arn:aws-cn:iam::aws:policy/AmazonEKS_CNI_Policy",
			"arn:aws-cn:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly",
		}

		assumeRolePolicy = pulumi.String(`{
		    "Version": "2012-10-17",
		    "Statement": [{
		        "Sid": "",
		        "Effect": "Allow",
		        "Principal": {
		            "Service": "ec2.amazonaws.com.cn"
		        },
		        "Action": "sts:AssumeRole"
		    }]
		}`)
	}

	for i, eksPolicy := range eksPolicies {
		_, err := iam.NewRolePolicyAttachment(ctx, fmt.Sprintf("rpa-%d", i), &iam.RolePolicyAttachmentArgs{
			PolicyArn: pulumi.String(eksPolicy),
			Role:      eksRole.Name,
		})
		if err != nil {
			return err
		}
	}

	nodeGroupRole, err := iam.NewRole(ctx, "nodegroup-iam-role", &iam.RoleArgs{
		AssumeRolePolicy: assumeRolePolicy,
	})
	if err != nil {
		return err
	}

	for i, nodeGroupPolicy := range nodeGroupPolicies {
		_, err := iam.NewRolePolicyAttachment(ctx, fmt.Sprintf("ngpa-%d", i), &iam.RolePolicyAttachmentArgs{
			Role:      nodeGroupRole.Name,
			PolicyArn: pulumi.String(nodeGroupPolicy),
		})
		if err != nil {
			return err
		}
	}

	// Create a Security Group that we can use to actually connect to our cluster
	// https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/security-group-rules-reference.html
	sg, err := ec2.NewSecurityGroup(ctx, "mo-pulumi-sg", &ec2.SecurityGroupArgs{
		Description: pulumi.String("security group for ec2 nodes"),
		Name:        pulumi.String("mo-pulumi-sg"),
		VpcId:       vpc.ID(),
		Egress: ec2.SecurityGroupEgressArray{
			ec2.SecurityGroupEgressArgs{
				Protocol:   pulumi.String("-1"),
				FromPort:   pulumi.Int(0),
				ToPort:     pulumi.Int(0),
				CidrBlocks: pulumi.StringArray{pulumi.String("10.10.0.0/20")},
			},
		},
		Ingress: ec2.SecurityGroupIngressArray{
			ec2.SecurityGroupIngressArgs{
				Protocol:   pulumi.String("tcp"),
				FromPort:   pulumi.Int(80),
				ToPort:     pulumi.Int(80),
				CidrBlocks: pulumi.StringArray{pulumi.String("20.20.0.0/20")},
			},
		},
	}, pulumi.DependsOn([]pulumi.Resource{vpc, subnets[zoneNumber-1]}))
	if err != nil {
		return err
	}

	// Create EKS Cluster
	eksCluster, err := eks.NewCluster(ctx, "mo-pulumi-eks-cluster", &eks.ClusterArgs{
		RoleArn: pulumi.StringInput(eksRole.Arn),
		VpcConfig: &eks.ClusterVpcConfigArgs{
			PublicAccessCidrs: pulumi.StringArray{
				publicAccessCidrs,
			},
			SecurityGroupIds: pulumi.StringArray{
				sg.ID().ToStringOutput(),
			},
			SubnetIds: toSubnetsArray(subnets),
		},
	})
	if err != nil {
		return err
	}

	var nodeGroups []*eks.NodeGroup

	for i := 0; i < zoneNumber; i++ {
		ng, err := eks.NewNodeGroup(ctx, "mo-pulumi-ng-"+strconv.Itoa(i), &eks.NodeGroupArgs{
			ClusterName:   eksCluster.Name,
			NodeGroupName: pulumi.String("mo-pulumi-ng" + strconv.Itoa(i)),
			NodeRoleArn:   pulumi.StringInput(nodeGroupRole.Arn),
			SubnetIds:     toSubnetsArray(subnets),
			InstanceTypes: utils.ToPulumiStringArray(icfg.Types),
			ScalingConfig: eks.NodeGroupScalingConfigArgs{
				DesiredSize: pulumi.Int(1),
				MaxSize:     pulumi.Int(1),
				MinSize:     pulumi.Int(1),
			},
			DiskSize: pulumi.Int(icfg.diskSize),
			Labels: pulumi.StringMap{
				"Name": pulumi.String("mo-pulumi-ng" + strconv.Itoa(i)),
			},
		}, pulumi.DependsOn([]pulumi.Resource{eksCluster, subnets[zoneNumber-1]}))
		if err != nil {
			return err
		}

		nodeGroups = append(nodeGroups, ng)
	}

	ctx.Export("kubeconfig", generateKubeconfig(eksCluster.Endpoint,
		eksCluster.CertificateAuthority.Data().Elem(), eksCluster.Name))

	k8sProvider, err := kubernetes.NewProvider(ctx, "k8s", &kubernetes.ProviderArgs{
		Kubeconfig: generateKubeconfig(eksCluster.Endpoint, eksCluster.CertificateAuthority.Data().Elem(), eksCluster.Name),
	}, pulumi.DependsOn([]pulumi.Resource{nodeGroups[0]}))
	if err != nil {
		return err
	}

	if installMOCluster || installOp {
		opNS, err := createNS(ctx, k8sProvider, "matrixone-operator")
		if err != nil {
			return err
		}

		_, err = helm.NewRelease(ctx, "operator-helm", &helm.ReleaseArgs{
			Chart: pulumi.String("matrixone-operator"),
			RepositoryOpts: helm.RepositoryOptsArgs{
				Repo: pulumi.String("https://matrixorigin.github.io/matrixone-operator"),
			},
			Version:   pulumi.String("0.1.0"),
			Namespace: opNS.Metadata.Name(),
			SkipAwait: pulumi.BoolPtr(true),
		}, pulumi.Provider(k8sProvider), pulumi.DependsOn([]pulumi.Resource{opNS}))
		if err != nil {
			return err
		}

		if installMOCluster && !installOp {
			moNS, err := createNS(ctx, k8sProvider, "matrixone")
			if err != nil {
				return err
			}

			_, err = apiextensions.NewCustomResource(ctx, "mo-cluster", &apiextensions.CustomResourceArgs{
				ApiVersion: pulumi.String("matrixone.matrixorigin.cn/v1alpha1"),
				Kind:       pulumi.String("MatrixoneCluster"),
				Metadata: &metav1.ObjectMetaArgs{
					Name:      pulumi.String("mo"),
					Namespace: moNS.Metadata.Name(),
				},
				OtherFields: kubernetes.UntypedArgs{
					"spec": map[string]interface{}{
						"image":           pulumi.String("matrixorigin/matrixone:0.4.0"),
						"imagePullPolicy": pulumi.String("Always"),
						"replicas":        pulumi.Int(1),
						"requests": pulumi.Map{
							"cpu": pulumi.String("200m"),
						},
						"podName": pulumi.Map{
							"name": pulumi.String("POD_NAME"),
							"valueFrom": pulumi.Map{
								"fieldRef": pulumi.Map{
									"fieldPath": pulumi.String("metadata.name"),
								},
							},
						},
						"logVolumeCap":  pulumi.String("10Gi"),
						"dataVolumeCap": pulumi.String("10Gi"),
					},
				},
			}, pulumi.Provider(k8sProvider), pulumi.DependsOn([]pulumi.Resource{moNS}))
			if err != nil {
				return err
			}
		}

	}

	return nil
}

func toSubnetsArray(az []*ec2.Subnet) pulumi.StringArrayInput {
	var res []pulumi.StringInput

	for _, v := range az {
		res = append(res, v.ID().ToStringOutput())
	}

	return pulumi.StringArray(res)
}

func createNS(ctx *pulumi.Context, provider *kubernetes.Provider, ns string) (*corev1.Namespace, error) {
	n, err := corev1.NewNamespace(ctx, ns, &corev1.NamespaceArgs{
		Metadata: &metav1.ObjectMetaArgs{
			Name: pulumi.String(ns),
		},
	}, pulumi.Provider(provider))
	if err != nil {
		return n, err
	}

	return n, nil
}

//Create the KubeConfig Structure as per https://docs.aws.amazon.com/eks/latest/userguide/create-kubeconfig.html
func generateKubeconfig(clusterEndpoint pulumi.StringOutput, certData pulumi.StringOutput, clusterName pulumi.StringOutput) pulumi.StringOutput {
	return pulumi.Sprintf(`{
        "apiVersion": "v1",
        "clusters": [{
            "cluster": {
                "server": "%s",
                "certificate-authority-data": "%s"
            },
            "name": "kubernetes",
        }],
        "contexts": [{
            "context": {
                "cluster": "kubernetes",
                "user": "aws",
            },
            "name": "aws",
        }],
        "current-context": "aws",
        "kind": "Config",
        "users": [{
            "name": "aws",
            "user": {
                "exec": {
                    "apiVersion": "client.authentication.k8s.io/v1beta1",
                    "command": "aws-iam-authenticator",
                    "args": [
                        "token",
                        "-i",
                        "%s",
                    ],
                },
            },
        }],
    }`, clusterEndpoint, certData, clusterName)
}

func ToPulumiStringArray(a []string) pulumi.StringArrayInput {
	var res []pulumi.StringInput

	for _, s := range a {
		res = append(res, pulumi.String(s))
	}

	return pulumi.StringArray(res)
}
```
